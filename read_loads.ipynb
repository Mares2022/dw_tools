{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def read_gemalen_sheet(filepath):\n",
    "    df = pd.read_excel(filepath, sheet_name=\"Gemalen\", skiprows=2)\n",
    "    # Remove first two rows\n",
    "    df = df.iloc[2:].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def clean_and_combine_duplicate_columns(df):\n",
    "    \"\"\"\n",
    "    Converts numeric columns and combines duplicate columns\n",
    "    (same base name before .1, .2, .3) by summing row-wise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Base names without suffix .1, .2, .3\n",
    "    base_names = df.columns.str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "    # Group using transpose (future-proof, no warnings)\n",
    "    df_combined = (\n",
    "        df.T\n",
    "        .groupby(base_names)   # group rows (former columns)\n",
    "        .sum()                 # sum within each group\n",
    "        .T                     # transpose back to original shape\n",
    "    )\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "def group_columns_by_kgm(columns):\n",
    "    groups = defaultdict(list)\n",
    "\n",
    "    for col in columns:\n",
    "        match = re.match(r\"(KGM\\d+)\", col)\n",
    "        if match:\n",
    "            kgm = match.group(1)\n",
    "            groups[kgm].append(col)\n",
    "\n",
    "    return dict(groups)\n",
    "\n",
    "def aggregate_by_grouped(df, grouped):\n",
    "    # Initialize new DataFrame with the same index as original\n",
    "    df_new = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for new_col, old_cols in grouped.items():\n",
    "        # Sum the old columns row-wise; ignore missing columns\n",
    "        existing_cols = [col for col in old_cols if col in df.columns]\n",
    "        df_new[new_col] = df[existing_cols].sum(axis=1)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def save_columns_to_csv(df, output_path, stations_ids, suffix=\"_discharge\"):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in stations_ids:\n",
    "            filename = f\"{col}{suffix}.csv\"\n",
    "            filepath = os.path.join(output_path, filename)\n",
    "            # Save with index\n",
    "            df[[col]].to_csv(filepath, sep=\";\")\n",
    "            print(f\"Saved: {filepath}\")\n",
    "\n",
    "def clean_numeric(df):\n",
    "    \"\"\"\n",
    "    Convert all columns of a DataFrame to numeric floats.\n",
    "    - Handles values like '<0.05' by taking the number and dividing by 2.\n",
    "    - Non-numeric values are converted to NaN.\n",
    "    \"\"\"\n",
    "    \n",
    "    def process_value(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        if isinstance(x, str) and x.startswith('<'):\n",
    "            try:\n",
    "                num = float(x[1:])  # remove '<' and convert\n",
    "                return num / 2\n",
    "            except:\n",
    "                return np.nan\n",
    "        try:\n",
    "            return float(x)\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    # Apply to all columns\n",
    "    df_numeric = df.map(process_value)\n",
    "    return df_numeric\n",
    "\n",
    "def clean_and_sort_mps(df, column=\"MPS.Omschrijving\"):\n",
    "    \"\"\"\n",
    "    Cleans date-like strings that contain suffixes like '.1', '.2',\n",
    "    converts the column to datetime, and returns the dataframe sorted by it.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure column exists\n",
    "    if column not in df.columns:\n",
    "        raise KeyError(f\"Column '{column}' not found in dataframe.\")\n",
    "    \n",
    "    # Remove anything like .1, .2, .33, etc. at the end of the string\n",
    "    df[column] = df[column].astype(str).str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "    \n",
    "    # Convert to datetime (assuming format dd-mm-yyyy)\n",
    "    df[column] = pd.to_datetime(df[column], format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "\n",
    "    # Sort rows by this column\n",
    "    df = df.sort_values(by=column).reset_index(drop=True)\n",
    "\n",
    "    # Set column as index\n",
    "    df = df.set_index(column)\n",
    "\n",
    "    df  = clean_numeric(df)\n",
    "\n",
    "    # Drop the rows where all values are NaN with the exception of the index\n",
    "    df = df.dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "\n",
    "    # Set index as column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    counts = df[column].value_counts()\n",
    "\n",
    "    # Find the dates that appear more than once\n",
    "    duplicates = counts[counts > 1]\n",
    "\n",
    "    if not duplicates.empty:\n",
    "        print(\"WARNING: Multiple rows with the same datetime found:\")\n",
    "        # Group by datetime and take mean of numeric columns\n",
    "        df = df.groupby(column).mean().reset_index()\n",
    "        print(duplicates)\n",
    "    else:\n",
    "        print(\"No duplicate datetimes found.\")\n",
    "\n",
    "    # Set column as index\n",
    "    df = df.set_index(column)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rename_columns(df, substance_dict):\n",
    "    \"\"\"\n",
    "    Rename columns in df according to substance_dict.\n",
    "    Only keeps mappings where the substance has a non-zero name.\n",
    "    Handles missing columns gracefully.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "        substance_dict (dict): Dictionary mapping new names to existing columns\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with renamed columns\n",
    "    \"\"\"\n",
    "    # Keep only valid substances (non-zero values)\n",
    "    valid_substances = {k: v for k, v in substance_dict.items() if v != 0}\n",
    "\n",
    "    # Build a rename dictionary: only for columns that exist in df\n",
    "    rename_dict = {v: k for k, v in valid_substances.items() if v in df.columns}\n",
    "\n",
    "    # Rename columns\n",
    "    df_renamed = df.rename(columns=rename_dict)\n",
    "\n",
    "    return df_renamed\n",
    "\n",
    "def rename_highest_mean_duplicate(df, colname, new_name):\n",
    "    \"\"\"\n",
    "    Rename ONLY one duplicated column with highest mean.\n",
    "    Handles columns with identical names by tracking occurrence index.\n",
    "    \"\"\"\n",
    "    # Collect the positions of columns with this name\n",
    "    indices = [i for i, c in enumerate(df.columns) if c == colname]\n",
    "\n",
    "    if len(indices) < 2:\n",
    "        return df  # nothing to do\n",
    "\n",
    "    # Compute means per duplicated occurrence\n",
    "    means = {}\n",
    "    for occ, col_idx in enumerate(indices):\n",
    "        means[occ] = df.iloc[:, col_idx].mean()\n",
    "\n",
    "    # Which occurrence has the highest mean?\n",
    "    highest_occ = max(means, key=means.get)\n",
    "\n",
    "    # Build new column names\n",
    "    new_columns = df.columns.tolist()\n",
    "\n",
    "    # Rename only that occurrence\n",
    "    col_to_rename_idx = indices[highest_occ]\n",
    "    new_columns[col_to_rename_idx] = new_name\n",
    "\n",
    "    # Apply back\n",
    "    df = df.copy()\n",
    "    df.columns = new_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2423f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sheet: KGM134\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "Processing sheet: KGM135\n",
      "  Found 7 columns: ['Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 1 columns: ['koolstof organisch']\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  8\n",
      "\n",
      "Processing sheet: KGM136\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "Processing sheet: KGM145\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "Processing sheet: KGM159\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "Processing sheet: KGM182\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "Processing sheet: KGM38\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "Processing sheet: KGM51\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "Processing sheet: KGM53\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "Processing sheet: KGM58\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "WARNING: Multiple rows with the same datetime found:\n",
      "MPS.Omschrijving\n",
      "2018-08-02    2\n",
      "Name: count, dtype: int64\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "Processing sheet: KGM67\n",
      "  Found 8 columns: ['koolstof organisch', 'Onopgeloste bestandsdelen', 'ammonium', 'som nitraat en nitriet', 'stikstof totaal', 'fosfaat', 'fosfor totaal', 'zuurstof']\n",
      "  Missing 0 columns: []\n",
      "No duplicate datetimes found.\n",
      "The number of rows in the sub dataframe is:  12\n",
      "The number of columns in the sub dataframe is:  9\n",
      "\n",
      "✔ Combined summary saved to:\n",
      "P:\\ltv-natuur-schelde-slib-waq\\ecolmod\\02_preprocessing\\loads\\summary_all_sheets.csv\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"P:\\ltv-natuur-schelde-slib-waq\\ecolmod\\02_preprocessing\\loads\\data waterkwaliteit gemalen Westerschelde.xlsx\"\n",
    "\n",
    "# Your substance dictionary\n",
    "substance_dict = {\n",
    "    \"DOC\": \"koolstof organisch\",\n",
    "    \"POC1\": \"Onopgeloste bestandsdelen\",\n",
    "    \"NH4\": \"ammonium\",\n",
    "    \"NO3\": \"som nitraat en nitriet\",\n",
    "    \"PON1\": \"stikstof totaal\",\n",
    "    \"PO4\": \"fosfaat\",\n",
    "    \"POP1\": \"fosfor totaal\",\n",
    "    \"Si\": 0,\n",
    "    \"Opal\": 0,\n",
    "    \"OXY\": \"zuurstof\",\n",
    "    \"Diat\": 0,\n",
    "    \"Green\": 0\n",
    "}\n",
    "\n",
    "# Keep only substances that have meaningful names (not zeros)\n",
    "valid_substances = {k: v for k, v in substance_dict.items() if v != 0}\n",
    "\n",
    "output_path = (\n",
    "    r\"P:\\ltv-natuur-schelde-slib-waq\\ecolmod\\02_preprocessing\\loads\"\n",
    ")\n",
    "summary_file = os.path.join(output_path, \"summary_all_sheets.csv\")\n",
    "\n",
    "# Create an empty list to collect all rows\n",
    "summary_rows = []\n",
    "stations_ids = []\n",
    "\n",
    "with pd.ExcelFile(file_path) as xls:\n",
    "    for sheet_name in xls.sheet_names[:]:  # limit to first sheet for now\n",
    "        print(f\"\\nProcessing sheet: {sheet_name.split('_')[-1]}\")\n",
    "\n",
    "        df = pd.read_excel(xls, sheet_name=sheet_name, skiprows=5)\n",
    "        if df.empty:\n",
    "            print(\"  (Sheet is empty after skipping rows)\")\n",
    "            continue\n",
    "\n",
    "        # Transpose and clean\n",
    "        df = df.transpose()\n",
    "        df.reset_index(inplace=True)\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df[1:].reset_index(drop=True)\n",
    "\n",
    "        available_cols = df.columns.tolist()\n",
    "\n",
    "        # Matching columns\n",
    "        found = [v for v in valid_substances.values() if v in available_cols]\n",
    "        not_found = [v for v in valid_substances.values() if v not in available_cols]\n",
    "\n",
    "        print(f\"  Found {len(found)} columns: {found}\")\n",
    "        print(f\"  Missing {len(not_found)} columns: {not_found}\")\n",
    "\n",
    "        # Build the extraction column list\n",
    "        extract_cols = [\"MPS.Omschrijving\"] + found\n",
    "\n",
    "        # Check MPS exists\n",
    "        if \"MPS.Omschrijving\" not in available_cols:\n",
    "            print(\"  WARNING: 'MPS.Omschrijving' not found in this sheet.\")\n",
    "            continue\n",
    "\n",
    "        df_sub = df[extract_cols]\n",
    "\n",
    "        df_sub = clean_and_sort_mps(df_sub, \"MPS.Omschrijving\")\n",
    "\n",
    "        df_sub = rename_columns(df_sub, substance_dict)\n",
    "\n",
    "        df_sub = rename_highest_mean_duplicate(df_sub, \"OXY\", \"OXY_saturation\")\n",
    "\n",
    "        df_sub.reset_index(inplace=True)\n",
    "        df_sub.rename(columns={\"MPS.Omschrijving\": \"date\"}, inplace=True)\n",
    "        df_sub.set_index(\"date\", inplace=True)\n",
    "\n",
    "        # Save the sub dataframe to a csv file\n",
    "        df_sub.to_csv(os.path.join(output_path,f\"{sheet_name.split('_')[-1]}_substance.csv\"), sep=\";\")\n",
    "\n",
    "        stations_ids.append(sheet_name.split('_')[-1])\n",
    "\n",
    "        print(\"The number of rows in the sub dataframe is: \", df_sub.shape[0])\n",
    "        print(\"The number of columns in the sub dataframe is: \", df_sub.shape[1])\n",
    "\n",
    "        # Append summary row\n",
    "        summary_rows.append({\n",
    "            \"sheet\": sheet_name,\n",
    "            \"found_columns\": \", \".join(found),\n",
    "            \"missing_columns\": \", \".join(not_found),\n",
    "            \"n_found\": len(found),\n",
    "            \"n_missing\": len(not_found)\n",
    "        })\n",
    "\n",
    "# Convert collected rows into a DataFrame\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Save as a single CSV file using semicolon as separator\n",
    "summary_df.to_csv(summary_file, index=False, sep=\";\")\n",
    "\n",
    "print(f\"\\n✔ Combined summary saved to:\\n{summary_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50009e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"P:\\ltv-natuur-schelde-slib-waq\\ecolmod\\02_preprocessing\\loads\\Debieten_gemalen_stuwen_westerschelde_2018.xlsx\"\n",
    "\n",
    "df_gemalen = read_gemalen_sheet(filepath)\n",
    "df_gemalen.rename(columns={\"Unnamed: 0\": \"date\"}, inplace=True)\n",
    "df_gemalen.set_index(\"date\", inplace=True)\n",
    "df_gemalen  = clean_numeric(df_gemalen)\n",
    "cols = df_gemalen.columns  # or your list\n",
    "\n",
    "grouped = group_columns_by_kgm(cols)\n",
    "grouped\n",
    "\n",
    "df_clean = clean_and_combine_duplicate_columns(df_gemalen)\n",
    "df_aggregated = aggregate_by_grouped(df_gemalen, grouped)\n",
    "save_columns_to_csv(df_aggregated, output_path, stations_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26aa910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read gemalen sheet\n",
    "from dwq_utilities import read_waarde_sheet\n",
    "import os\n",
    "import pandas as pd\n",
    "data_dir = r\"P:\\ltv-natuur-schelde-slib-waq\\ecolmod\\02_preprocessing\\loads\"\n",
    "waarde_path = os.path.join(data_dir, \"Concentraties_en_vrachten_in_de_waterlijn.xlsx\")\n",
    "\n",
    "df = pd.read_excel(waarde_path, sheet_name=\"effluent rwzi Waarde\", skiprows=9)\n",
    "df = df.iloc[3:].reset_index(drop=True)\n",
    "# Remove last 10 rows\n",
    "df = df.iloc[:-11].reset_index(drop=True)\n",
    "# Remove columns Unnamed\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Change column Parameter to datetime using var time_col and  new_time_col\n",
    "time_col = \"Parameter\"\n",
    "new_time_col = \"datetime\"\n",
    "df[new_time_col] = pd.to_datetime(df[time_col])\n",
    "df.drop(columns=[time_col], inplace=True)\n",
    "# Set time_col as index\n",
    "df.set_index(new_time_col, inplace=True)\n",
    "\n",
    "# Convert all columns to numeric\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df\n",
    "\n",
    "\n",
    "substance_dict = {\n",
    "    \"DOC\": \"CZV\",        # Chemisch zuurstofverbruik\n",
    "    \"POC1\": \"OB\",        # Onopgeloste bestandsdelen\n",
    "    \"NH4\": \"NH4\",        # Ammonium\n",
    "    \"NO3\": \"NO3\",        # Nitraat\n",
    "    \"PON1\": \"Ntot\",      # Stikstof totaal\n",
    "    \"PO4\": \"PO4\",        # Fosfaat\n",
    "    \"POP1\": \"Ptot\",      # Fosfor totaal\n",
    "    \"Si\": 0,\n",
    "    \"Opal\": 0,\n",
    "    \"OXY\": \"TZV\",        # Totaal zuurstofverbruik\n",
    "    \"Diat\": 0,\n",
    "    \"Green\": 0,\n",
    "    \"Q\": \"Q\"\n",
    "}\n",
    "\n",
    "# Keep only substances that have meaningful names (not zeros)\n",
    "valid_substances = {k: v for k, v in substance_dict.items() if v != 0}\n",
    "valid_substances\n",
    "\n",
    "# Keep only valid substances and rename with keys of valid_substances\n",
    "# Filter dataframe columns to keep only those present in valid_substances values\n",
    "df_filtered = df[list(valid_substances.values())].copy()\n",
    "\n",
    "# Rename columns from new names → original keys (model names)\n",
    "rename_dict = {v: k for k, v in valid_substances.items()}\n",
    "df_filtered.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "df_filtered\n",
    "# Save to csv\n",
    "df_filtered.to_csv(os.path.join(data_dir, \"waarde_effluent_rwzi.csv\"), sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idp-dashboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
